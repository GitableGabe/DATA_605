---
title: 'DATA 605: Computational Mathematics '
author: "Gabriel Campos"
date: "Last edited `r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    df_print: paged
    toc: true
    toc_depth: 6
  geometry: left=0.5cm,right=0.5cm,top=1cm,bottom=2cm
  pdf_document:
    latex_engine: xelatex
    toc: true
    toc_depth: 6
  html_notebook: default
urlcolor: blue
---

# Library

```{r, message=FALSE, warning=FALSE}
library(dplyr)
library(e1071)
library(ggplot2)
library(MASS)
library(readr)
```


**Final Examination: Business Analytics and Data Science**

# Instructions:

You are required to complete this take-home final examination by the end of the last week of class. Your solutions should be uploaded in **pdf** format as a knitted document (with graphs, content, commentary, etc. in the pdf). This project will showcase your ability to apply the concepts learned throughout the course.

The dataset you will use for this examination is provided as [retail data.csv](https://brightspace.cuny.edu/content/enforced/437177-SPS01_DATA_605_1249_15536/synthetic_retail_data.csv), which contains the following variables:

- Product_ID: Unique identifier for each product.
- Sales: Simulated sales numbers (in dollars).
- Inventory_Levels: Inventory levels for each product.
- Lead_Time_Days: The lead time in days for each product.
- Price: The price of each product.
- Seasonality_Index: An index representing seasonality.

# Problem 1: 

**Business Risk and Revenue Modeling**

**Context:** You are a data scientist working for a retail chain that models sales, inventory levels, and the impact of pricing and seasonality on revenue. Your task is to analyze various distributions that can describe sales variability and forecast potential revenue.

## Data Load

```{r, message=FALSE}
retail_df <- read_csv("synthetic_retail_data.csv")
```


### Part 1:

**Empirical and Theoretical Analysis of Distributions (5 Points)**

**Task:**

### 1. 

**Generate and Analyze Distributions:**

- **X ~ Sales:** Consider the Sales variable from the dataset. Assume it follows a Gamma distribution and estimate its shape and scale parameters using the fitdistr function from the MASS package.
- **Y ~ Inventory Levels:** Assume that the sum of inventory levels across similar products follows a Lognormal distribution. Estimate the parameters for this distribution.
- **Z ~ Lead Time:** Assume that Lead_Time_Days follows a Normal distribution. Estimate the mean and standard deviation.
Calculate Empirical Expected Value and Variance:

Calculate the empirical mean and variance for all three variables.
Compare these empirical values with the theoretical values derived from the estimated distribution parameters.

```{r}
head(retail_df)
```

```{r}
glimpse(retail_df)
```

```{r}
summary(retail_df)
```

#### X ~ Sales


```{r}
# Isolate Sales data
sales_retail_df <- retail_df$Sales
summary(sales_retail_df)
sum(sales_retail_df<0)
sum(is.na(sales_retail_df))
shapiro.test(sales_retail_df)
```

```{r, warning=FALSE}
ggplot(retail_df, aes(x = Sales)) +
  geom_histogram(aes(y = ..density..),
                 bins = 30, fill = "steelblue",
                 alpha = 0.5) +
  geom_density(color = "red", size = 1) +
  ggtitle("Histogram and Density Plot of Sales") +
  theme_classic()
```


```{r}
qqnorm(sales_retail_df, 
       main = "Q-Q Plot of Sales")
qqline(sales_retail_df, 
       col = "red")
```

```{r}
boxplot(sales_retail_df,
        main = "Boxplot of Sales Data")
```

##### Initial analysis

- For our **Sales** data our $Mean > Median$ ($636.92>533.54$) which indicates that our data is right skewed and not normalized. This is supported by our Histogram, our Q-Q plot and the Shapiro test's $p-value$ of less than 0.05.
- No $NAs$ are noted with the **Sales** data 
- Our range for the values within **Sales** is 25.57 to 2447.49, encompassing a wide range.
- Our Box plot indicates that there are outliers, primarily for values $>1000$


##### fitdstr Sales Solution

Assume $X \sim Gamma(\alpha, \beta)$ the parameter *"gamma"* will be used with *fitdistr()*. 

```{r}
sales_gamma_fit <- fitdistr(sales_retail_df, "gamma")
print(sales_gamma_fit)
```

Considering no NAs or negative values were noted in our original data set, the $NaNs \ produced$ warning, is likely a result of the right-skewed data or from our outliers. I will remove the outliers to see if it removes the warning. Regardless, dealing with these outliers should improve precision.

The below steps should remove values above our 99% quantile or below the 1%

```{r, warning=FALSE}
# compute quantiles at 1% and and 99%
sales_retail_quantiles <- 
  quantile(sales_retail_df, probs =c(0.01,0.99))
# remove outliers below the 1% and above 99%
sales_retail_df_clean<- sales_retail_df[
  sales_retail_df >= sales_retail_quantiles[1] &
    sales_retail_df <= sales_retail_quantiles[2]
]
sales_gamma_fit_clean <- fitdistr(sales_retail_df_clean, "gamma")
print(sales_gamma_fit_clean)
```

The cleaned model still creates an error therefore I would like to see visually how well the values fit.

```{r}
hist(sales_retail_df_clean,
     breaks = 30,
     probability = TRUE, 
     main = "Fitted Gamma Distribution",
     xlab = "Sales",
     col = "steelblue")

curve(dgamma(x,
             shape = 1.8349640762,
             rate = 0.0028810166), 
      col = "red",
      lwd = 2, 
      add = TRUE)

legend("topright",
       legend = c("Data",
                  "Fitted Gamma PDF"), 
       col = c("lightblue",
               "red"), lwd = 2)
```



```{r}
hist(sales_retail_df,
     breaks = 30,
     probability = TRUE, 
     main = "Fitted Gamma Distribution",
     xlab = "Sales",
     col = "royalblue")

curve(dgamma(x,
             shape = 2.0323543224,
             rate = 0.0032518379 ), 
      col = "red",
      lwd = 2, 
      add = TRUE)

legend("topright",
       legend = c("Data",
                  "Fitted Gamma PDF"), 
       col = c("lightblue",
               "red"), lwd = 2)

```

Visually, both values seem to match the $Sales$ behavior. By calculating the absolute difference in mean, skewness and variance, I might get a better indication on which gamma distribution and gamma parameters, better emulates the datas behavior.

```{r, fig.height=5}
cmp_metrics <- c("Mean", "Variance", "Skewness")

cmp_data_values <- c(617.595, 165599.6, 0.8891198)

# Original Gamma differences
cmp_shape1 <- 2.0323543224

cmp_rate1 <- 0.0032518379

cmp_original_gamma_values <- 
  c(cmp_shape1 / cmp_rate1,
    cmp_shape1 / (cmp_rate1^2),
    2 / sqrt(cmp_shape1))

cmp_original_differences <- 
  abs(cmp_original_gamma_values - cmp_data_values)

# New Gamma differences
cmp_shape2 <- 1.8349640762
cmp_rate2 <- 0.0028810166

cmp_new_gamma_values <- 
  c(cmp_shape2 / cmp_rate2,
    cmp_shape2 / (cmp_rate2^2),
    2 / sqrt(cmp_shape2))
cmp_new_differences <-
  abs(cmp_new_gamma_values - cmp_data_values)

# Prepare data for ggplot
plot_data <- data.frame(
  Metric = rep(cmp_metrics,
               times = 2),
  Difference = 
    c(cmp_original_differences,
                 cmp_new_differences),
  Gamma = rep(c("Original Gamma",
                "New Gamma"), 
              each = length(cmp_metrics))
)

# Create the clustered bar plot
ggplot(plot_data, aes(x = Metric, y = Difference, fill = Gamma)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.9)) +
  geom_text(aes(label = round(Difference, 2)), 
            position = position_dodge(width = 0.9), 
            vjust = -0.5, size = 3.5) +
  labs(
    title = "Comparison of Differences from Data Metrics",
    x = "Metric",
    y = "Absolute Difference"
  ) +
  scale_fill_manual(values = c("Original Gamma" = "steelblue", "New Gamma" = "royalblue")) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),
    legend.title = element_blank()
  )

```

Based on these results the original gamma parameters of 1.8349640762 and 0.0028810166 are the more accurate fit.

```{r, echo=FALSE}
rm(list = ls(pattern = "^cmp_|plot_data|_clean$|_quantiles$"))
```

##### Mean and Variance (X~Sales)

Our Empirical mean and variance is just 

```{r}
sales_emp_mean<-mean(sales_retail_df)
sales_emp_var<-var(sales_retail_df)
```

and our theoretical mean and variance is calculate as 

$\mu_{gamma}=\frac{\alpha}{\beta}$

$\sigma^2_{gamma}=\frac{\alpha}{\beta^2}$ or $\frac{shape}{rate^2}$

```{r}
sales_gamma_shape <- sales_gamma_fit$estimate["shape"]
sales_gamma_rate <- sales_gamma_fit$estimate["rate"]

sales_theo_gamma_mean <- sales_gamma_shape / sales_gamma_rate
sales_theo_gamma_var <- sales_gamma_shape/ (sales_gamma_rate^2)
```

```{r}
comparison_Sales <- data.frame(
  Metric = c("Mean", "Variance"),
  Empirical = c(sales_emp_mean, sales_emp_var),
  Theoretical = c(sales_theo_gamma_mean, sales_theo_gamma_var)
)
```

##### Answer

**The shape parameter of 1.8349640762 and the rate parameter of 0.0028810166 define the best-fit Gamma distribution for the data.**

**Our Empirical and Theoretical, Variance and Mean are as follow:**

```{r, echo=FALSE}
print(comparison_Sales)
```

```{r}
rm(list = ls(pattern = "^sales|^comparison"))
```


#### Y ~ Inventory Levels

```{r}
inv_retail_df <- retail_df$Inventory_Levels
summary(inv_retail_df)
sum(inv_retail_df<0)
sum(is.na(inv_retail_df))
shapiro.test(inv_retail_df)
```

```{r}
ggplot(retail_df, aes(x = Inventory_Levels )) +
  geom_histogram(aes(y = ..density..),
                 bins = 30, fill = "steelblue",
                 alpha = 0.5) +
  geom_density(color = "red", size = 1) +
  ggtitle("Histogram and Density Plot of Inventory Levels") +
  theme_classic()
```

```{r}
qqnorm(inv_retail_df, 
       main = "Q-Q Plot of Sales")
qqline(inv_retail_df, 
       col = "red")
```

```{r}
boxplot(inv_retail_df,
        main = "Boxplot of Sales Data")
```


##### Initial analysis

- No NAs found in *Inventory_Levels*
- No values below 0 for the *Inventory_Levels* values.
- $488.55 \ (Mean) > 483.72 \ (Median)$ suggests the data may be right skewed.
- Shapiro test had a $p-value =0.4646$. This is below 0.5, suggesting it is not normalized, however it is relatively close to being normal.
- Q-Q plot and, Histogram and Density plot, show the data as near normal.

##### fitdistr Inventory Levels

Since we are assuming the Inventory Levels across products follows a Lognormal distribution  $(X \sim Lognormal(\mu,\sigma^2))$, the parameter for *fitdistr()* we use is *lognormal*. Since we are explicitly looking for the sum of inventory levels across similar products, we will *sum* can consider finding the values for the individual *Product_ID*'s before evaluating the distribution.

```{r}
retail_df %>%
  group_by(Inventory_Levels) %>%
  summarise(Count = n()) %>%
  filter(Count > 1)
```

Since it appears that all *Product_ID*'s are unique I will refrain from using the sum.

The parameters of this distribution will ultimately be $\mu_{log}$ and $\sigma_{log}$

```{r}
inv_lognormal <- 
  fitdistr(inv_retail_df,"lognormal")

inv_log_mean <- inv_lognormal$estimate["meanlog"]
inv_log_var <- inv_lognormal$estimate["sdlog"]

print(inv_lognormal)
```

```{r}
# Histogram for Inventory Levels
hist(inv_retail_df,
     breaks = 30,
     probability = TRUE, 
     main = "Fitted Lognormal Distribution",
     xlab = "Inventory Levels",
     col = "slateblue")

# Overlay the fitted lognormal curve
curve(dlnorm(x,
             meanlog = inv_log_mean,
             sdlog = inv_log_var), 
      col = "red",
      lwd = 2, 
      add = TRUE)

# Add legend
legend("topright",
       legend = c("Data", "Fitted Lognormal PDF"), 
       col = c("lightblue", "red"), 
       lwd = 2)

```

##### Mean and Variance (Y~Inventory Levels)

*Theoretical Mean* or $E[x]$ of a random variable $X \sim Lognormal(\mu,\sigma^2)$ is equal to $e^{\mu+\frac{\sigma^2}{2}}$ and its theoretical variance is $(e^{\sigma^2}-1) e^{2\mu+\sigma^2}$

```{r}
# Empirical statistics
empirical_mean <- mean(retail_df$Inventory_Levels)
empirical_variance <- var(retail_df$Inventory_Levels)

# Theoretical mean and variance for lognormal distribution
theoretical_mean <- 
  exp(inv_log_mean +
        (inv_log_var^2) / 2)

theoretical_variance <- 
  (exp(inv_log_var^2) - 1) * 
  exp(2 * inv_log_mean + inv_log_var^2)

# # Print results
# cat("Empirical Mean:", empirical_mean, "\n")
# cat("Theoretical Mean:", theoretical_mean, "\n")
# cat("Empirical Variance:", empirical_variance, "\n")
# cat("Theoretical Variance:", theoretical_variance, "\n")

comparison_Inventory_Level <- data.frame(
  Metric = c("Mean", "Variance"),
  Empirical = c(empirical_mean, empirical_variance),
  Theoretical = c(theoretical_mean, theoretical_variance)
)

```

##### Answer

The parameters for the Inventory Level distribution, $(X \sim Lognormal(\mu,\sigma^2))$ are $\mu_{log}=6.13303680$ and $\sigma^2_{log}=0.3633273$

**Our Empirical and Theoretical, Variance and Mean are as follow:**

```{r}
print(comparison_Inventory_Level)
```

```{r}
rm(list = ls()[!grepl("^retail", ls())])
```


#### Z ~ Lead Time

```{r}
ltd_retail_df <- retail_df$Lead_Time_Days
summary(ltd_retail_df)
sum(ltd_retail_df<0)
sum(is.na(ltd_retail_df))
shapiro.test(ltd_retail_df)
```

```{r}
ggplot(retail_df, aes(x = Lead_Time_Days )) +
  geom_histogram(aes(y = ..density..),
                 bins = 30, fill = "steelblue",
                 alpha = 0.5) +
  geom_density(color = "red", size = 1) +
  ggtitle("Histogram and Density Plot of Lead Times") +
  theme_classic()
```



## 2. 

# Part 2:

**Probability Analysis and Independence Testing (5 Points)**

**Task:**

## 1.

**Empirical Probabilities:** For the Lead_Time_Days variable (assumed to be normally distributed), calculate the following empirical probabilities:

- $P(Z> \mu | Z > \mu - \sigma)$
- $P(Z> \mu + \sigma > Z > \mu)$
- $P(Z> \mu + 2\sigma > Z > \mu)$

## 2.

**Correlation and Independence:**

- Investigate the correlation between Sales and Price. Create a contingency table using quartiles of Sales and Price, and then evaluate the marginal and joint probabilities.
- Use Fisher’s Exact Test and the Chi-Square Test to check for independence between Sales and Price. Discuss which test is most appropriate and why.

# Problem 2

**Advanced Forecasting and Optimization (Calculus) in Retail**

**Context:** You are working for a large retail chain that wants to optimize pricing, inventory management, and sales forecasting using data-driven strategies. Your task is to use regression, statistical modeling, and calculus-based methods to make informed decisions.

## Part 1

**Descriptive and Inferential Statistics for Inventory Data (5 Points)**

**Task:**

## 1.

**Inventory Data Analysis:**

- Generate univariate descriptive statistics for the Inventory_Levels and Sales variables.
- Create appropriate visualizations such as histograms and scatterplots for Inventory_Levels, Sales, and Price.
- Compute a correlation matrix for Sales, Price, and Inventory_Levels.
- Test the hypotheses that the correlations between the variables are zero and provide a 95% confidence interval.

## 2.

**Discussion:**

- Explain the meaning of your findings and discuss the implications of the correlations for inventory management. Would you be concerned about multicollinearity in a potential regression model? Why or why not?

## Part 2

**Linear Algebra and Pricing Strategy (5 Points)**

**Task:**

## 1.

**Price Elasticity of Demand:**

- Use linear regression to model the relationship between Sales and Price (assuming Sales as the dependent variable).
- Invert the correlation matrix from your model, and calculate the precision matrix.
- Discuss the implications of the diagonal elements of the precision matrix (which are variance inflation factors).
- Perform LU decomposition on the correlation matrix and interpret the results in the context of price elasticity.

## Part 3:

**Calculus-Based Probability & Statistics for Sales Forecasting (5 Points)**

**Task:**

## 1.

**Sales Forecasting Using Exponential Distribution:**

- Identify a variable in the dataset that is skewed to the right (e.g., Sales or Price) and fit an exponential distribution to this data using the fitdistr function.
- Generate 1,000 samples from the fitted exponential distribution and compare a histogram of these samples with the original data's histogram.
- Calculate the 5th and 95th percentiles using the cumulative distribution function (CDF) of the exponential distribution.
- Compute a 95% confidence interval for the original data assuming normality and compare it with the empirical percentiles.

## 2.

**Discussion:**

- Discuss how well the exponential distribution models the data and what this implies for forecasting future sales or pricing. Consider whether a different distribution might be more appropriate.

## Part 4

**Regression Modeling for Inventory Optimization (10 Points)**

**Task:**

## 1.

**Multiple Regression Model:**

- Build a multiple regression model to predict Inventory_Levels based on Sales, Lead_Time_Days, and Price.
- Provide a full summary of your model, including coefficients, R-squared value, and residual analysis.

## 2.

**Optimization:**

- Use your model to optimize inventory levels for a peak sales season, balancing minimizing stockouts with minimizing overstock. 

# References

[Statology fitdistr-r](https://www.statology.org/fitdistr-r/)

[rdocumentation MASS package fitdistr](https://www.rdocumentation.org/packages/MASS/versions/7.3-61/topics/fitdistr)

[Statology - fit gamma distribution to dataset in r](https://www.statology.org/fit-gamma-distribution-to-dataset-in-r/)

[Wiki Gamma Distribution](https://en.wikipedia.org/wiki/Gamma_distribution)

[rdocumentation qualtile](https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/quantile)

[statlect lognormal distribution](https://www.statlect.com/probability-distributions/log-normal-distribution)